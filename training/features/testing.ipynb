{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3238fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = ['GC=F', 'DX-Y.NYB', '^GSPC', '^TNX', '^VIX']\n",
    "START_DATE = '2001-01-01'\n",
    "TARGET_COL = 'Gold_Price'\n",
    "\n",
    "# --- 1. Data Retrieval and Preprocessing ---\n",
    "def get_and_clean_data(tickers, start_date):\n",
    "    \"\"\"Downloads data, selects 'Close' prices, and cleans up the DataFrame.\"\"\"\n",
    "    print(\"Downloading data...\")\n",
    "    all_data = yf.download(tickers, start=start_date, interval='1d')\n",
    "\n",
    "    # Isolate 'Close' prices and clean up\n",
    "    df = all_data['Close'].dropna(axis=1, how='all')\n",
    "    df = df.ffill()\n",
    "    df = df.rename(columns={'GC=F': TARGET_COL})\n",
    "\n",
    "    # Drop any raw ticker columns that failed to load\n",
    "    for ticker in tickers:\n",
    "        if ticker in df.columns and ticker != TARGET_COL:\n",
    "            if df[ticker].isnull().all():\n",
    "                 df = df.drop(columns=[ticker])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317363c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martijn\\AppData\\Local\\Temp\\ipykernel_17096\\1320821376.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  all_data = yf.download(tickers, start=start_date, interval='1d')\n",
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "df_raw = get_and_clean_data(TICKERS, START_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory of 'features' to sys.path\n",
    "training_dir = Path.cwd().parent\n",
    "if str(training_dir) not in sys.path:\n",
    "\tsys.path.insert(0, str(training_dir))\n",
    "\n",
    "from features.build_features import build_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fe3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_features(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6860f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'Gold_Price_L0',\n",
    "    'Gold_Price_L5',\n",
    "    'Gold_Price_L20',\n",
    "    'Gold_Price_10D_MA',\n",
    "    'Gold_Price_50D_MA',\n",
    "    'Gold_Log_Return',\n",
    "    'Gold_Log_Return_20D_Vol',\n",
    "    'DXY_Level',\n",
    "    '10Y_Yield_Level',\n",
    "    'VIX_Level',\n",
    "    'SPX_Log_Return'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'day',\n",
    "    'month',\n",
    "    'year',\n",
    "    'dayofweek',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "preprocessor_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {\n",
    "    \"rf\": Pipeline([(\"prep\", preprocessor_tree),\n",
    "                    (\"model\", RandomForestRegressor())]),\n",
    "    \"xgb\": Pipeline([(\"prep\", preprocessor_tree),\n",
    "                     (\"model\", XGBRegressor(eval_metric=\"rmse\"))]),\n",
    "    \"nn\": Pipeline([(\"prep\", preprocessor_linear),\n",
    "                    (\"model\", MLPRegressor(max_iter=1000))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2870e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "\n",
    "def train_all_models(df, n_splits=5):\n",
    "\n",
    "    print(\"ğŸ”§ Building features...\")\n",
    "    df_features = build_features(df)\n",
    "\n",
    "    X = df_features.drop(\"Target_Gold_Price\", axis=1)\n",
    "    y = df_features[\"Target_Gold_Price\"]\n",
    "\n",
    "    print(f\"ğŸ“Š Total rows after feature engineering: {len(df_features)}\")\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    print(f\"â³ Starting training for {len(candidates)} models with {n_splits} time-series splits...\\n\")\n",
    "\n",
    "    for name, pipeline in candidates.items():\n",
    "        print(f\"====================\")\n",
    "        print(f\"ğŸš€ Training model: {name}\")\n",
    "        print(f\"====================\")\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "            print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
    "            print(f\"Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            with mlflow.start_run(run_name=f\"{name}_fold{fold}\"):\n",
    "\n",
    "                print(\"ğŸ§  Fitting model...\")\n",
    "                pipeline.fit(X_train, y_train)\n",
    "\n",
    "                print(\"ğŸ“ˆ Predicting...\")\n",
    "                preds = pipeline.predict(X_test)\n",
    "\n",
    "                rmse = mean_squared_error(y_test, preds)\n",
    "                print(f\"ğŸ“‰ RMSE (fold {fold+1}): {rmse:.4f}\")\n",
    "\n",
    "                mlflow.log_metric(\"RMSE\", rmse)\n",
    "                scores.append(rmse)\n",
    "\n",
    "                rsquared = pipeline.score(X_test, y_test)\n",
    "                mlflow.log_metric(\"R2\", rsquared)\n",
    "\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        results[name] = avg_score\n",
    "\n",
    "        print(f\"\\nâœ… Finished model: {name}\")\n",
    "        print(f\"ğŸ† Average RMSE: {avg_score:.4f}\\n\")\n",
    "\n",
    "    print(\"ğŸ‰ All models trained successfully!\")\n",
    "    print(\"ğŸ“Š Final Results:\", results)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Building features...\n",
      "ğŸ“Š Total rows after feature engineering: 6253\n",
      "â³ Starting training for 3 models with 5 time-series splits...\n",
      "\n",
      "====================\n",
      "ğŸš€ Training model: rf\n",
      "====================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Train size: 1043, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 1): 103535.0804\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Train size: 2085, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 2): 1186988.6241\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Train size: 3127, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 3): 700845.7542\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Train size: 4169, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 4): 604344.5015\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Train size: 5211, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 5): 1610669.7977\n",
      "\n",
      "âœ… Finished model: rf\n",
      "ğŸ† Average RMSE: 841276.7516\n",
      "\n",
      "====================\n",
      "ğŸš€ Training model: xgb\n",
      "====================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Train size: 1043, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 1): 102004.2166\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Train size: 2085, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 2): 1102894.3658\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Train size: 3127, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 3): 374735.8311\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Train size: 4169, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 4): 367882.2632\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Train size: 5211, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 5): 1721261.8357\n",
      "\n",
      "âœ… Finished model: xgb\n",
      "ğŸ† Average RMSE: 733755.7025\n",
      "\n",
      "====================\n",
      "ğŸš€ Training model: nn\n",
      "====================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Train size: 1043, Test size: 1042\n",
      "ğŸ§  Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Ironhack\\projects\\gold-price-mlops\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 1): 11467.9500\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Train size: 2085, Test size: 1042\n",
      "ğŸ§  Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Ironhack\\projects\\gold-price-mlops\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 2): 9684.5610\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Train size: 3127, Test size: 1042\n",
      "ğŸ§  Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Ironhack\\projects\\gold-price-mlops\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 3): 325.6013\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Train size: 4169, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 4): 307.9784\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Train size: 5211, Test size: 1042\n",
      "ğŸ§  Fitting model...\n",
      "ğŸ“ˆ Predicting...\n",
      "ğŸ“‰ RMSE (fold 5): 908.4217\n",
      "\n",
      "âœ… Finished model: nn\n",
      "ğŸ† Average RMSE: 4538.9025\n",
      "\n",
      "ğŸ‰ All models trained successfully!\n",
      "ğŸ“Š Final Results: {'rf': 841276.7515957551, 'xgb': 733755.7024791832, 'nn': 4538.902482630095}\n"
     ]
    }
   ],
   "source": [
    "result = train_all_models(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267af32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
